{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python388jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
      "display_name": "Python 3.8.8 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Run TCAV.ipynb",
      "provenance": []
    },
    "metadata": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v88fM4ciYYde"
      },
      "source": [
        "# Running TCAV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-RlU8wNYYdj"
      },
      "source": [
        "This notebook walks you through an example application of the TCAV library step-by-step to understand which human interpretable texture concepts (e.g. stripes, dots, zigzags) are important to the image classifier GoogleNet's (a.k.a. Inception v1) prediction of some target object you decide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1zIj8-aYYdj"
      },
      "source": [
        "## Install required packages\n",
        "\n",
        "To run through this notebook in the interim, you are encouraged to utilize a `virtualenv` or `conda` environment for installing and working with the required packages to avoid any dependency and compatability issues with different versions of packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "sIHww5CuYYdk"
      },
      "source": [
        "%pip install tensorflow\n",
        "%pip install tcav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NT91qkMYYdk"
      },
      "source": [
        "## Download example models and images\n",
        "\n",
        "Open a terminal and run the following commands:\n",
        "\n",
        "```\n",
        "cd tcav/tcav_examples/image_models/imagenet\n",
        "\n",
        "OLD\n",
        "python download_and_make_datasets.py --source_dir=YOUR_PATH --number_of_images_per_folder=50 --number_of_random_folders=3\n",
        "```\n",
        "\n",
        "```\n",
        "python3 download_and_make_datasets.py --source_dir=IMGNET_DOWNLOAD --target=\"Egyptian cat\" --number_of_images_per_folder=10 --number_of_random_folders=3\n",
        "```\n",
        "\n",
        "This script will download the following content into separate folders into a directory you specify with the `--source_dir=` argument:\n",
        "\n",
        "**Images**\n",
        "*  ImageNet images for the target Zebra class\n",
        "*  [Broden dataset](http://netdissect.csail.mit.edu/) images for three concepts (e.g. striped, dotted, zigzagged)\n",
        "*  Random ImageNet class images used by TCAV for hypothesis testing of important concepts\n",
        "\n",
        "**Models**\n",
        "*  [Inception 5h model](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/inception5h.py)\n",
        "*  [Mobilenet V2 model](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlrLUu4zYYdl"
      },
      "source": [
        "## Import extensions and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS1ZjSZjYYdl"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4yP9kDlYYdl"
      },
      "source": [
        "import tcav.activation_generator as act_gen\n",
        "import tcav.cav as cav\n",
        "import tcav.model  as model\n",
        "import tcav.tcav as tcav\n",
        "import tcav.utils as utils\n",
        "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
        "import os \n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yitpnXmEYYdm"
      },
      "source": [
        "## TCAV step-by-step\n",
        "\n",
        "You will walk through the following steps below:\n",
        "\n",
        "1. **Store example images in each folder** (you have this if you ran the above)\n",
        " * images for each concept\n",
        " * images for the class/labels of interest\n",
        " * random images that will be negative examples when learning CAVs (images that probably don't belong to any concepts)\n",
        "2. **Write a model wrapper** (below uses example from tcav/model.py)\n",
        " * an instance of  ModelWrapper abstract class (in model.py). This tells TCAV class (tcav.py) how to communicate with your model (e.g., getting internal tensors)\n",
        "3. **Retrieve model activations** (below uses example from tcav/activation_generator.py)\n",
        " * an instance of ActivationGeneratorInterface that tells TCAV class how to load example data and how to get activations from the model\n",
        "4. Run TCAV and visualize scores for important concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjLK3pBYYdm"
      },
      "source": [
        "## Step 1: Store concept and target class images to local folders\n",
        "\n",
        "... and tell TCAV where they are.\n",
        "\n",
        "**source_dir**: where images of concepts, target class and random images (negative samples when learning CAVs) live. Each should be a sub-folder within this directory.\n",
        "\n",
        "Note that random image directories can be in any name. In this example, we are using `random500_0`, `random500_1`,.. for an arbitrary reason. \n",
        "\n",
        "You need roughly 50-200 images per concept and target class (10-20 pictures also tend to work, but 200 is pretty safe).\n",
        "\n",
        "\n",
        "**cav_dir**: directory to store CAVs (`None` if you don't want to store)\n",
        "\n",
        "**target, concept**: names of the target class (that you want to investigate) and concepts (strings) - these are folder names in source_dir\n",
        "\n",
        "**bottlenecks**: list of bottleneck names (intermediate layers in your model) that you want to use for TCAV. These names are defined in the model wrapper below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "EHabMnMNYYdm"
      },
      "source": [
        "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
        "\n",
        "# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n",
        "model_to_run = 'GoogleNet'  \n",
        "user = 'beenkim'\n",
        "# the name of the parent directory that results are stored (only if you want to cache)\n",
        "project_name = 'tcav_class_test'\n",
        "working_dir = \"/tmp/\" + user + '/' + project_name\n",
        "# where activations are stored (only if your act_gen_wrapper does so)\n",
        "activation_dir =  working_dir+ '/activations/'\n",
        "# where CAVs are stored. \n",
        "# You can say None if you don't wish to store any.\n",
        "cav_dir = working_dir + '/cavs/'\n",
        "# where the images live.\n",
        "\n",
        "# TODO: replace 'YOUR_PATH' with path to downloaded models and images. \n",
        "source_dir = '/Users/parkermitchell/Desktop/tcav3.0/tcav/tcav_examples/image_models/imagenet/IMGNET_DOWNLOAD'\n",
        "bottlenecks = [ 'mixed4c']  # @param \n",
        "      \n",
        "utils.make_dir_if_not_exists(activation_dir)\n",
        "utils.make_dir_if_not_exists(working_dir)\n",
        "utils.make_dir_if_not_exists(cav_dir)\n",
        "\n",
        "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
        "alphas = [0.1]   \n",
        "\n",
        "target = 'Egyptian cat'\n",
        "concepts = ['blotchy', 'dotted', 'banded', 'striped']\n",
        "# concepts = ['blotchy', 'dotted', 'banded', 'striped', 'bumpy', 'smeared', 'knitted', 'porous', 'pitted', 'fibrous', 'veined', 'perforated', 'woven', 'meshed', 'crosshatched', 'sprinkled', 'polka-dotted', 'marbled', 'stained', 'grid', 'gauzy', 'interlaced', 'frilly', 'zigzagged', 'spiralled', 'swirly', 'cracked', 'studded', 'matted', 'flecked', 'potholed', 'scaly', 'stratified', 'braided', 'lined', 'wrinkled', 'paisley', 'waffled', 'freckled', 'honeycombed', 'lacelike', 'chequered', 'crystalline', 'bubbly', 'grooved', 'pleated', 'cobwebbed']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_DfQqsAYYdn"
      },
      "source": [
        "## Step 2: Write your model wrapper\n",
        "\n",
        "The next step is to tell TCAV how to communicate with your model. See `model.GoogleNetWrapper_public ` for details.\n",
        "\n",
        "You can define a subclass of ModelWrapper abstract class to do this. Let me walk you thru what each function does (tho they are pretty self-explanatory).  This wrapper includes a lot of the functions that you already have, for example, `get_prediction`.\n",
        "\n",
        "### 2.1: Tensors from the graph: bottleneck tensors and ends\n",
        "First, store your bottleneck tensors in `self.bottlenecks_tensors` as a dictionary. You only need bottlenecks that you are interested in running TCAV with. Similarly, fill in `self.ends` dictionary with `input`, `logit` and `prediction` tensors.\n",
        "\n",
        "### 2.2: Define loss\n",
        "Get your loss tensor, and assigned it to `self.loss`. This is what TCAV uses to take directional derivatives. \n",
        "\n",
        "While doing so, you would also want to set \n",
        "```python\n",
        "self.y_input \n",
        "```\n",
        "this simply is a tensorflow place holder for the target index in the logit layer (e.g., 0 index for a dog, 1 for a cat).\n",
        "For multi-class classification, typically something like this works:\n",
        "\n",
        "```python\n",
        "self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
        "```\n",
        "\n",
        "For example, for a multiclass classifier, something like below would work. \n",
        "\n",
        "```python\n",
        "    # Construct gradient ops.\n",
        "    with g.as_default():\n",
        "      self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
        "\n",
        "      self.pred = tf.expand_dims(self.ends['prediction'][0], 0)\n",
        "\n",
        "      self.loss = tf.reduce_mean(\n",
        "          tf.nn.softmax_cross_entropy_with_logits(\n",
        "              labels=tf.one_hot(self.y_input, len(self.labels)),\n",
        "              logits=self.pred))\n",
        "    self._make_gradient_tensors()\n",
        "```\n",
        "\n",
        "### 2.3: Call _make_gradient_tensors in __init__() of your wrapper\n",
        "```python\n",
        "_make_gradient_tensors()  \n",
        "```\n",
        "does what you expect - given the loss and bottleneck tensors defined above, it adds gradient tensors.\n",
        "\n",
        "### 2.4: Fill in labels, image shapes and a model name.\n",
        "Get the mapping from labels (strings) to indice in the logit layer (int) in a dictionary format.\n",
        "\n",
        "```python\n",
        "def id_to_label(self, idx)\n",
        "def label_to_id(self, label)\n",
        "```\n",
        "\n",
        "Set your input image shape at  `self.image_shape`\n",
        "\n",
        "\n",
        "Set your model name to `self.model_name`\n",
        "\n",
        "You are done with writing the model wrapper! See the two example model wrapers, InceptionV3 and Googlenet in `tcav/model.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "hH-YQiEIYYdn"
      },
      "source": [
        "# Create TensorFlow session.\n",
        "sess = utils.create_session()\n",
        "\n",
        "# GRAPH_PATH is where the trained model is stored.\n",
        "GRAPH_PATH = source_dir + \"/inception5h/tensorflow_inception_graph.pb\"\n",
        "# LABEL_PATH is where the labels are stored. Each line contains one class, and they are ordered with respect to their index in \n",
        "# the logit layer. (yes, id_to_label function in the model wrapper reads from this file.)\n",
        "# For example, imagenet_comp_graph_label_strings.txt looks like:\n",
        "# dummy                                                                                      \n",
        "# kit fox\n",
        "# English setter\n",
        "# Siberian husky ...\n",
        "\n",
        "LABEL_PATH = source_dir + \"/inception5h/imagenet_comp_graph_label_strings.txt\"\n",
        "\n",
        "mymodel = model.GoogleNetWrapper_public(sess,\n",
        "                                        GRAPH_PATH,\n",
        "                                        LABEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY5kXbVAYYdo"
      },
      "source": [
        "## Step 3: Implement a class that returns activations (maybe with caching!)\n",
        "\n",
        "Lastly, you will implement a class of the ActivationGenerationInterface which TCAV uses to load example data for a given concept or target, call into your model wrapper and return activations. I pulled out this logic outside of mymodel because this step often takes the longest. By making it modular, you can cache your activations and/or parallelize your computations, as I have done in `ActivationGeneratorBase.process_and_load_activations` in `activation_generator.py`.\n",
        "\n",
        "\n",
        "The `process_and_load_activations` method of the activation generator must return a dictionary of activations that has concept or target name as  a first key, and the bottleneck name as a second key. So something like:\n",
        "\n",
        "```python\n",
        "{concept1: {bottleneck1: [[0.2, 0.1, ....]]},\n",
        "concept2: {bottleneck1: [[0.1, 0.02, ....]]},\n",
        "target1: {bottleneck1: [[0.02, 0.99, ....]]}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmSyFxQbYYdo"
      },
      "source": [
        "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uABCWhp8YYdo"
      },
      "source": [
        "## Step 4: Run TCAV and visualize concept importance\n",
        "\n",
        "You are now ready to run TCAV! Let's do it.\n",
        "\n",
        "**num_random_exp**: number of experiments to confirm meaningful concept direction. TCAV will search for this many folders named `random500_0`, `random500_1`, etc. You can alternatively set the `random_concepts` keyword to be a list of folders of random concepts. Run at least 10-20 for meaningful tests. \n",
        "\n",
        "**random_counterpart**: as well as the above, you can optionally supply a single folder with random images as the \"positive set\" for statistical testing. Reduces computation time at the cost of less reliable random TCAV scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "tags": [
          "outputPrepend"
        ],
        "id": "F2FVOGSvYYdp"
      },
      "source": [
        "import absl\n",
        "absl.logging.set_verbosity(0)\n",
        "num_random_exp=15\n",
        "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs. \n",
        "mytcav = tcav.TCAV(sess,\n",
        "                   target,\n",
        "                   concepts,\n",
        "                   bottlenecks,\n",
        "                   act_generator,\n",
        "                   alphas,\n",
        "                   cav_dir=cav_dir,\n",
        "                   num_random_exp=num_random_exp)#10)\n",
        "print ('This may take a while... Go get coffee!')\n",
        "results = mytcav.run(run_parallel=False)\n",
        "print ('done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "tags": [],
        "id": "hjKVKa80YYdp",
        "outputId": "ff3cbebe-4edd-4342-cede-24dc10ce9d99"
      },
      "source": [
        "utils_plot.plot_results(results, num_random_exp=num_random_exp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tcav_scores = utils_plot.plot_results(results, num_random_exp=num_random_exp)\n",
        "print(tcav_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max(tcav_scores, key=lambda x: x[1])"
      ]
    }
  ]
}